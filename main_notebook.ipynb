{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfa8f6058f07c39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Human Value Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fe4c58990df29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9333223475180",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:24.033429690Z",
     "start_time": "2023-12-10T15:44:22.590898611Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utilities import *\n",
    "from models.bertOne import BertOne\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix\n",
    "from models.randomUniformClassifier import RandomUniformClassifier\n",
    "from models.majorityCalssifier import MajorityClassifier\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from drTorch.callbacks import EarlyStopper\n",
    "\n",
    "from drTorch.metrics import F1_Score\n",
    "from drTorch.utilities import *\n",
    "from drTorch.wrappers import OptimizerWrapper\n",
    "from drTorch.wrappers import Criterion\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print('Device: %s' % device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:24.096125404Z",
     "start_time": "2023-12-10T15:44:24.079686168Z"
    }
   },
   "id": "29dcff5a5f7bfb48"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9f2553b6aeb5c7f9"
  },
  {
   "cell_type": "markdown",
   "id": "ef2ee4b05f9169d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining constants and flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb44f1708144b43a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:24.104628652Z",
     "start_time": "2023-12-10T15:44:24.091618349Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS AND DATAFRAME CREATION\n",
    "DATA_DIR = \"data\"\n",
    "ARGUMENTS_DIR = os.path.join(DATA_DIR, \"arguments\")\n",
    "LABELS_DIR = os.path.join(DATA_DIR, \"labels\")\n",
    "\n",
    "# CONSTANTS \n",
    "N_LABELS = 4\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 1\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "CLASS_2_ONE_HOT = {class_label: np.eye(N_CLASSES)[i].astype(float).tolist() for i, class_label in enumerate(range(N_CLASSES))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32a409b1e982e3dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3723181a1d5f1aad"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910abdb6bbf8ee01",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:24.158032932Z",
     "start_time": "2023-12-10T15:44:24.105528159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's visualize the data: \n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              Conclusion       Stance  \\\nArgument ID                                                             \nA01002                       We should ban human cloning  in favor of   \nA01005                           We should ban fast food  in favor of   \nA01006       We should end the use of economic sanctions      against   \nA01007              We should abolish capital punishment      against   \nA01008                     We should ban factory farming      against   \n\n                                                       Premise  \nArgument ID                                                     \nA01002       we should ban human cloning as it will only ca...  \nA01005       fast food should be banned because it is reall...  \nA01006       sometimes economic sanctions are the only thin...  \nA01007       capital punishment is sometimes the only optio...  \nA01008       factory farming allows for the production of c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Conclusion</th>\n      <th>Stance</th>\n      <th>Premise</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>We should ban human cloning</td>\n      <td>in favor of</td>\n      <td>we should ban human cloning as it will only ca...</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>We should ban fast food</td>\n      <td>in favor of</td>\n      <td>fast food should be banned because it is reall...</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>We should end the use of economic sanctions</td>\n      <td>against</td>\n      <td>sometimes economic sanctions are the only thin...</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>We should abolish capital punishment</td>\n      <td>against</td>\n      <td>capital punishment is sometimes the only optio...</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>We should ban factory farming</td>\n      <td>against</td>\n      <td>factory farming allows for the production of c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "             Self-direction: thought  Self-direction: action  Stimulation  \\\nArgument ID                                                                 \nA01002                             0                       0            0   \nA01005                             0                       0            0   \nA01006                             0                       0            0   \nA01007                             0                       0            0   \nA01008                             0                       0            0   \n\n             Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\nArgument ID                                                                    \nA01002              0            0                 0                 0     0   \nA01005              0            0                 0                 0     0   \nA01006              0            0                 1                 0     0   \nA01007              0            0                 0                 0     0   \nA01008              0            0                 0                 0     0   \n\n             Security: personal  Security: societal  Tradition  \\\nArgument ID                                                      \nA01002                        0                   1          0   \nA01005                        1                   0          0   \nA01006                        0                   1          0   \nA01007                        0                   1          0   \nA01008                        1                   0          0   \n\n             Conformity: rules  Conformity: interpersonal  Humility  \\\nArgument ID                                                           \nA01002                       0                          0         0   \nA01005                       0                          0         0   \nA01006                       0                          0         0   \nA01007                       1                          0         0   \nA01008                       0                          0         0   \n\n             Benevolence: caring  Benevolence: dependability  \\\nArgument ID                                                    \nA01002                         0                           0   \nA01005                         0                           0   \nA01006                         0                           0   \nA01007                         0                           0   \nA01008                         1                           0   \n\n             Universalism: concern  Universalism: nature  \\\nArgument ID                                                \nA01002                           0                     0   \nA01005                           0                     0   \nA01006                           0                     0   \nA01007                           1                     0   \nA01008                           1                     0   \n\n             Universalism: tolerance  Universalism: objectivity  \nArgument ID                                                      \nA01002                             0                          0  \nA01005                             0                          0  \nA01006                             0                          0  \nA01007                             0                          0  \nA01008                             0                          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Self-direction: thought</th>\n      <th>Self-direction: action</th>\n      <th>Stimulation</th>\n      <th>Hedonism</th>\n      <th>Achievement</th>\n      <th>Power: dominance</th>\n      <th>Power: resources</th>\n      <th>Face</th>\n      <th>Security: personal</th>\n      <th>Security: societal</th>\n      <th>Tradition</th>\n      <th>Conformity: rules</th>\n      <th>Conformity: interpersonal</th>\n      <th>Humility</th>\n      <th>Benevolence: caring</th>\n      <th>Benevolence: dependability</th>\n      <th>Universalism: concern</th>\n      <th>Universalism: nature</th>\n      <th>Universalism: tolerance</th>\n      <th>Universalism: objectivity</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert files in dataframes\n",
    "train_arg_df, val_arg_df, test_arg_df = create_dfs(ARGUMENTS_DIR)\n",
    "train_labels_df, val_labels_df, test_labels_df = create_dfs(LABELS_DIR)\n",
    "\n",
    "print(\"Let's visualize the data: \")\n",
    "display(train_arg_df.head(5))\n",
    "display(train_labels_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mapping labels to level-3 categories"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2f8c631fc728aa8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "998d8c9bd76a90f4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:24.966843400Z",
     "start_time": "2023-12-10T15:44:24.155170522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training labels after the mapping are the following: \n"
     ]
    },
    {
     "data": {
      "text/plain": "             Openess_to_change  Self_enhancement  Conservation  \\\nArgument ID                                                      \nA01002                       0                 0             1   \nA01005                       0                 0             1   \nA01006                       0                 1             1   \nA01007                       0                 0             1   \nA01008                       0                 0             1   \n...                        ...               ...           ...   \nE08016                       0                 1             1   \nE08017                       0                 0             1   \nE08018                       0                 0             0   \nE08019                       0                 0             1   \nE08020                       1                 1             1   \n\n             Self_transcendence  \nArgument ID                      \nA01002                        0  \nA01005                        0  \nA01006                        0  \nA01007                        0  \nA01008                        1  \n...                         ...  \nE08016                        1  \nE08017                        1  \nE08018                        1  \nE08019                        1  \nE08020                        1  \n\n[5393 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Openess_to_change</th>\n      <th>Self_enhancement</th>\n      <th>Conservation</th>\n      <th>Self_transcendence</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>E08016</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08017</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08018</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08019</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08020</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5393 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = define_mapping()\n",
    "train_labels_df, val_labels_df, test_labels_df = map_to_level_3(mapping, train_labels_df, val_labels_df, test_labels_df) \n",
    "\n",
    "print(\"The training labels after the mapping are the following: \")\n",
    "train_labels_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### One-hot encoding, tokenization and data loaders building"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45a3b5162e441c9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "columns_to_consider = [\"Conclusion\", \"Premise\"]\n",
    "\n",
    "train_labels_tensor = torch.tensor([[CLASS_2_ONE_HOT[element] for element in row] for row in train_labels_df.values])\n",
    "val_labels_tensor = torch.tensor([[CLASS_2_ONE_HOT[element] for element in row] for row in val_labels_df.values])\n",
    "test_labels_tensor = torch.tensor([[CLASS_2_ONE_HOT[element] for element in row] for row in test_labels_df.values])\n",
    "\n",
    "max_length = calculate_max_length(train_arg_df, columns_to_consider, tokenizer)\n",
    "\n",
    "train_arg_df = encode(train_arg_df, tokenizer, max_length, columns_to_consider)\n",
    "val_arg_df = encode(val_arg_df, tokenizer, max_length, columns_to_consider)\n",
    "test_arg_df = encode(test_arg_df, tokenizer, max_length, columns_to_consider)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.481659515Z",
     "start_time": "2023-12-10T15:44:24.963047562Z"
    }
   },
   "id": "35e75074e5c73c20"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "train_loader_C = get_data_loader_test(batch_size=BATCH_SIZE,\n",
    "                                      shuffle=True,\n",
    "                                      data=train_arg_df.loc[:, \"Conclusion\"],\n",
    "                                      labels=train_labels_tensor)\n",
    "\n",
    "val_loader_C = get_data_loader_test(batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,\n",
    "                                    data=val_arg_df.loc[:, \"Conclusion\"],\n",
    "                                    labels=val_labels_tensor)\n",
    "\n",
    "# todo aggiungi gli altri data loader (CS and CSP), capire come passarli al modello senza fare casini\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.501427430Z",
     "start_time": "2023-12-10T15:44:28.483482371Z"
    }
   },
   "id": "17b535b1f9b68afd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9b4d8eb2b9080d"
  },
  {
   "cell_type": "markdown",
   "id": "31dbdf03bd612820",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Models Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3848b4411be166",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  1) Random uniform classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f51d9c86bef3a0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.518766597Z",
     "start_time": "2023-12-10T15:44:28.502888010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"# Create an instance of the random uniform classifier\\nrandom_classifier = RandomUniformClassifier()\\n\\n# Make predictions on the test set\\ny_pred = random_classifier.predict(test_arg_df, NUM_CLASSES)\\n\\n# average F1 on the different column singularly taken \\nf1 = avg_f1_score(test_labels_df, y_pred)\\nprint(f'Average F1 on the different column singularly taken: {f1}')\""
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create an instance of the random uniform classifier\n",
    "random_classifier = RandomUniformClassifier()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_classifier.predict(test_arg_df, NUM_CLASSES)\n",
    "\n",
    "# average F1 on the different column singularly taken \n",
    "f1 = avg_f1_score(test_labels_df, y_pred)\n",
    "print(f'Average F1 on the different column singularly taken: {f1}')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acdfbf96891d7f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.586588267Z",
     "start_time": "2023-12-10T15:44:28.516564317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"# Create an instance of the random uniform classifier\\nrandom_classifier = RandomUniformClassifier()\\n\\n# Make predictions on the test set\\ny_pred = random_classifier.predict(test_arg_df, NUM_CLASSES)\\n\\n# Evaluate the accuracy\\naccuracy = accuracy_score(test_labels_df, y_pred) #todo sostituire con F1 score\\n\\nf1_random = f1_score(test_labels_df, y_pred, average='macro')\\n\\ncm = multilabel_confusion_matrix(test_labels_df, y_pred)\\n\\nprint(accuracy,f1_random)\\nprint(cm)\\n\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create an instance of the random uniform classifier\n",
    "random_classifier = RandomUniformClassifier()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_classifier.predict(test_arg_df, NUM_CLASSES)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(test_labels_df, y_pred) #todo sostituire con F1 score\n",
    "\n",
    "f1_random = f1_score(test_labels_df, y_pred, average='macro')\n",
    "\n",
    "cm = multilabel_confusion_matrix(test_labels_df, y_pred)\n",
    "\n",
    "print(accuracy,f1_random)\n",
    "print(cm)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db911208037aa18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  1) Majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4563d2862bce6247",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.587071047Z",
     "start_time": "2023-12-10T15:44:28.559833403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"majority_classifier = MajorityClassifier()\\n\\n# Train the majority classifier (even though in practice, no training is needed)\\nmajority_classifier.fit(train_labels_df)\\n\\n# Make predictions on the test set\\ny_pred = majority_classifier.predict(test_labels_df)\\n\\n# average F1 on the different column singularly taken \\nf1 = avg_f1_score(test_labels_df, y_pred)\\nprint(f'Average F1 on the different column singularly taken: {f1}')\\n\""
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"majority_classifier = MajorityClassifier()\n",
    "\n",
    "# Train the majority classifier (even though in practice, no training is needed)\n",
    "majority_classifier.fit(train_labels_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = majority_classifier.predict(test_labels_df)\n",
    "\n",
    "# average F1 on the different column singularly taken \n",
    "f1 = avg_f1_score(test_labels_df, y_pred)\n",
    "print(f'Average F1 on the different column singularly taken: {f1}')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d01b312639fa4593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.587254514Z",
     "start_time": "2023-12-10T15:44:28.560103266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"majority_classifier = MajorityClassifier()\\n\\n# Train the majority classifier (though <in practice, no training is needed)\\nmajority_classifier.fit(test_labels_df)  # todo capire su quale dataset fare il fit\\n\\n# Make predictions on the test set\\ny_pred = majority_classifier.predict(test_labels_df)\\n\\n# Evaluate the accuracy and f1\\naccuracy = accuracy_score(test_labels_df, y_pred)\\nf1_majority = f1_score(test_labels_df, y_pred, average='macro', zero_division=np.nan)\\n\\ncm = multilabel_confusion_matrix(test_labels_df, y_pred)\\n\\nprint(accuracy,f1_majority)\\nprint(cm)\\n\""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"majority_classifier = MajorityClassifier()\n",
    "\n",
    "# Train the majority classifier (though <in practice, no training is needed)\n",
    "majority_classifier.fit(test_labels_df)  # todo capire su quale dataset fare il fit\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = majority_classifier.predict(test_labels_df)\n",
    "\n",
    "# Evaluate the accuracy and f1\n",
    "accuracy = accuracy_score(test_labels_df, y_pred)\n",
    "f1_majority = f1_score(test_labels_df, y_pred, average='macro', zero_division=np.nan)\n",
    "\n",
    "cm = multilabel_confusion_matrix(test_labels_df, y_pred)\n",
    "\n",
    "print(accuracy,f1_majority)\n",
    "print(cm)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed615adcd88b156c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  3) Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:28.587804948Z",
     "start_time": "2023-12-10T15:44:28.562964728Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_test = OptimizerWrapper(torch.optim.Adam, identifier=f'lr={10}', optimizer_partial_params={'lr':10})\n",
    "criterion_test = Criterion('loss', loss_function=torch.nn.BCEWithLogitsLoss(reduction='none'), reduction_function=torch.mean)\n"
   ],
   "id": "185abecdef2d8b0"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "bert1 = BertOne().to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:30.088074728Z",
     "start_time": "2023-12-10T15:44:28.576493089Z"
    }
   },
   "id": "271801a5e0e06727"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "635d1212a0713b57",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:30.314058786Z",
     "start_time": "2023-12-10T15:44:30.090776027Z"
    }
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/rick/PycharmProjects/NLP_homework_2/.weights_memory'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileExistsError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#todo: il fit non funziona perchè va modificata la loss dalla classe Criterion in modo tale da renderla compatibile con le tuple e non solo con i tensori\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m bert1_history \u001B[38;5;241m=\u001B[39m \u001B[43mbert1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader_C\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader_C\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mF1_Score\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mF1_macro\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_LABELS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmacro\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                          \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mearly_stopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEarlyStopper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mF1_macro\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrestore_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/NLP_homework_2/drTorch/modules.py:146\u001B[0m, in \u001B[0;36mTrainableModule.fit\u001B[0;34m(self, train_loader, val_loader, criterion, metrics, optimizer, num_epochs, early_stopper, aggregate_loss_on_dataset, verbose)\u001B[0m\n\u001B[1;32m    143\u001B[0m iterations_per_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m early_stopper \u001B[38;5;129;01mand\u001B[39;00m early_stopper\u001B[38;5;241m.\u001B[39mrestore_weights:\n\u001B[0;32m--> 146\u001B[0m     \u001B[43mearly_stopper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m    149\u001B[0m     start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/PycharmProjects/NLP_homework_2/drTorch/callbacks.py:95\u001B[0m, in \u001B[0;36mEarlyStopper.create_directory\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_directory\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     89\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;124;03m    Create a hidden directory to store weights history.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124;03m    the directory was renamed by default as '.weights_memory'\u001B[39;00m\n\u001B[1;32m     92\u001B[0m \n\u001B[1;32m     93\u001B[0m \u001B[38;5;124;03m    :return: None\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 95\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_directory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen os>:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n",
      "\u001B[0;31mFileExistsError\u001B[0m: [Errno 17] File exists: '/home/rick/PycharmProjects/NLP_homework_2/.weights_memory'"
     ]
    }
   ],
   "source": [
    "#todo: il fit non funziona perchè va modificata la loss dalla classe Criterion in modo tale da renderla compatibile con le tuple e non solo con i tensori\n",
    "\n",
    "bert1_history = bert1.fit(train_loader=train_loader_C, \n",
    "                          val_loader=val_loader_C, \n",
    "                          criterion=criterion_test, \n",
    "                          metrics=[F1_Score('F1_macro', N_LABELS, mode='macro')], \n",
    "                          optimizer=optimizer_test,\n",
    "                          #early_stopper=EarlyStopper(monitor='F1_macro', patience=4, delta=0, mode='max', restore_weights=True),\n",
    "                          num_epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(bert1_history)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:30.319340527Z",
     "start_time": "2023-12-10T15:44:30.315320851Z"
    }
   },
   "id": "d915e3277493320a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Test sul modello\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "output = model(**encoded_input)\n",
    "\n",
    "\n",
    "p_d = BertOne()\n",
    "output1 = p_d(**encoded_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T15:44:30.356476756Z",
     "start_time": "2023-12-10T15:44:30.356181235Z"
    }
   },
   "id": "829599ba89a99187"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
