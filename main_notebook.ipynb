{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebfa8f6058f07c39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Human Value Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fe4c58990df29",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e9333223475180",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:26.598511017Z",
     "start_time": "2023-12-13T16:49:24.630412505Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import transformers\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utilities import *\n",
    "from models.bertOne import BertOne\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix\n",
    "from models.randomUniformClassifier import RandomUniformClassifier\n",
    "from models.majorityCalssifier import MajorityClassifier\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from drTorch.callbacks import EarlyStopper\n",
    "\n",
    "from drTorch.metrics import F1_Score\n",
    "from drTorch.metrics import F1_Score_Multi_Labels\n",
    "from drTorch.utilities import *\n",
    "from drTorch.wrappers import OptimizerWrapper\n",
    "from drTorch.wrappers import Criterion\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29dcff5a5f7bfb48",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:26.633824238Z",
     "start_time": "2023-12-13T16:49:26.591813954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "print('Device: %s' % device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2553b6aeb5c7f9",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef2ee4b05f9169d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining constants and flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb44f1708144b43a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:26.648100694Z",
     "start_time": "2023-12-13T16:49:26.630654126Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS AND DATAFRAME CREATION\n",
    "DATA_DIR = \"data\"\n",
    "ARGUMENTS_DIR = os.path.join(DATA_DIR, \"arguments\")\n",
    "LABELS_DIR = os.path.join(DATA_DIR, \"labels\")\n",
    "\n",
    "BERT_MODELS_DIRECTORY = \"bert_models\"\n",
    "BERT_VERSIONS=[\"bert-base-uncased\"]\n",
    "\n",
    "# CONSTANTS \n",
    "N_LABELS = 4\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 1\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "CLASS_2_ONE_HOT = {class_label: np.eye(N_CLASSES)[i].astype(float).tolist() for i, class_label in enumerate(range(N_CLASSES))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a409b1e982e3dd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723181a1d5f1aad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910abdb6bbf8ee01",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:26.710344035Z",
     "start_time": "2023-12-13T16:49:26.647624498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's visualize the data: \n"
     ]
    },
    {
     "data": {
      "text/plain": "                                              Conclusion       Stance  \\\nArgument ID                                                             \nA01002                       We should ban human cloning  in favor of   \nA01005                           We should ban fast food  in favor of   \nA01006       We should end the use of economic sanctions      against   \nA01007              We should abolish capital punishment      against   \nA01008                     We should ban factory farming      against   \n\n                                                       Premise  \nArgument ID                                                     \nA01002       we should ban human cloning as it will only ca...  \nA01005       fast food should be banned because it is reall...  \nA01006       sometimes economic sanctions are the only thin...  \nA01007       capital punishment is sometimes the only optio...  \nA01008       factory farming allows for the production of c...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Conclusion</th>\n      <th>Stance</th>\n      <th>Premise</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>We should ban human cloning</td>\n      <td>in favor of</td>\n      <td>we should ban human cloning as it will only ca...</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>We should ban fast food</td>\n      <td>in favor of</td>\n      <td>fast food should be banned because it is reall...</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>We should end the use of economic sanctions</td>\n      <td>against</td>\n      <td>sometimes economic sanctions are the only thin...</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>We should abolish capital punishment</td>\n      <td>against</td>\n      <td>capital punishment is sometimes the only optio...</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>We should ban factory farming</td>\n      <td>against</td>\n      <td>factory farming allows for the production of c...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "             Self-direction: thought  Self-direction: action  Stimulation  \\\nArgument ID                                                                 \nA01002                             0                       0            0   \nA01005                             0                       0            0   \nA01006                             0                       0            0   \nA01007                             0                       0            0   \nA01008                             0                       0            0   \n\n             Hedonism  Achievement  Power: dominance  Power: resources  Face  \\\nArgument ID                                                                    \nA01002              0            0                 0                 0     0   \nA01005              0            0                 0                 0     0   \nA01006              0            0                 1                 0     0   \nA01007              0            0                 0                 0     0   \nA01008              0            0                 0                 0     0   \n\n             Security: personal  Security: societal  Tradition  \\\nArgument ID                                                      \nA01002                        0                   1          0   \nA01005                        1                   0          0   \nA01006                        0                   1          0   \nA01007                        0                   1          0   \nA01008                        1                   0          0   \n\n             Conformity: rules  Conformity: interpersonal  Humility  \\\nArgument ID                                                           \nA01002                       0                          0         0   \nA01005                       0                          0         0   \nA01006                       0                          0         0   \nA01007                       1                          0         0   \nA01008                       0                          0         0   \n\n             Benevolence: caring  Benevolence: dependability  \\\nArgument ID                                                    \nA01002                         0                           0   \nA01005                         0                           0   \nA01006                         0                           0   \nA01007                         0                           0   \nA01008                         1                           0   \n\n             Universalism: concern  Universalism: nature  \\\nArgument ID                                                \nA01002                           0                     0   \nA01005                           0                     0   \nA01006                           0                     0   \nA01007                           1                     0   \nA01008                           1                     0   \n\n             Universalism: tolerance  Universalism: objectivity  \nArgument ID                                                      \nA01002                             0                          0  \nA01005                             0                          0  \nA01006                             0                          0  \nA01007                             0                          0  \nA01008                             0                          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Self-direction: thought</th>\n      <th>Self-direction: action</th>\n      <th>Stimulation</th>\n      <th>Hedonism</th>\n      <th>Achievement</th>\n      <th>Power: dominance</th>\n      <th>Power: resources</th>\n      <th>Face</th>\n      <th>Security: personal</th>\n      <th>Security: societal</th>\n      <th>Tradition</th>\n      <th>Conformity: rules</th>\n      <th>Conformity: interpersonal</th>\n      <th>Humility</th>\n      <th>Benevolence: caring</th>\n      <th>Benevolence: dependability</th>\n      <th>Universalism: concern</th>\n      <th>Universalism: nature</th>\n      <th>Universalism: tolerance</th>\n      <th>Universalism: objectivity</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert files in dataframes\n",
    "train_arg_df, val_arg_df, test_arg_df = create_dfs(ARGUMENTS_DIR)\n",
    "train_labels_df, val_labels_df, test_labels_df = create_dfs(LABELS_DIR)\n",
    "\n",
    "print(\"Let's visualize the data: \")\n",
    "display(train_arg_df.head(5))\n",
    "display(train_labels_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8c631fc728aa8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Mapping labels to level-3 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998d8c9bd76a90f4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:27.652078205Z",
     "start_time": "2023-12-13T16:49:26.707442116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training labels after the mapping are the following: \n"
     ]
    },
    {
     "data": {
      "text/plain": "             Openess_to_change  Self_enhancement  Conservation  \\\nArgument ID                                                      \nA01002                       0                 0             1   \nA01005                       0                 0             1   \nA01006                       0                 1             1   \nA01007                       0                 0             1   \nA01008                       0                 0             1   \n...                        ...               ...           ...   \nE08016                       0                 1             1   \nE08017                       0                 0             1   \nE08018                       0                 0             0   \nE08019                       0                 0             1   \nE08020                       1                 1             1   \n\n             Self_transcendence  \nArgument ID                      \nA01002                        0  \nA01005                        0  \nA01006                        0  \nA01007                        0  \nA01008                        1  \n...                         ...  \nE08016                        1  \nE08017                        1  \nE08018                        1  \nE08019                        1  \nE08020                        1  \n\n[5393 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Openess_to_change</th>\n      <th>Self_enhancement</th>\n      <th>Conservation</th>\n      <th>Self_transcendence</th>\n    </tr>\n    <tr>\n      <th>Argument ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A01002</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01005</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01006</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01007</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>A01008</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>E08016</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08017</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08018</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08019</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E08020</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5393 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = define_mapping()\n",
    "train_labels_df, val_labels_df, test_labels_df = map_to_level_3(mapping, train_labels_df, val_labels_df, test_labels_df) \n",
    "\n",
    "print(\"The training labels after the mapping are the following: \")\n",
    "train_labels_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3b5162e441c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### One-hot encoding, tokenization and data loaders building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "if os.path.exists(BERT_MODELS_DIRECTORY):\n",
    "    bert_versions_paths = os.listdir(BERT_MODELS_DIRECTORY)\n",
    "else:    \n",
    "    bert_versions_paths = download_bert_models(BERT_MODELS_DIRECTORY, BERT_VERSIONS)  \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:27.653218918Z",
     "start_time": "2023-12-13T16:49:27.616721709Z"
    }
   },
   "id": "1dad71e1264e68ca"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35e75074e5c73c20",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:49:33.779643702Z",
     "start_time": "2023-12-13T16:49:27.639849821Z"
    }
   },
   "outputs": [],
   "source": [
    "model_inputs = {\"C\":[\"Conclusion\"], \"CP\":[\"Conclusion\", \"Premise\"], \"CPS\":[\"Conclusion\", \"Premise\", \"Stance\"]}\n",
    "\n",
    "dataloader_train_C, dataloader_val_C, dataloader_test_C  = build_dataloaders(train_df=train_arg_df, \n",
    "                                                                             val_df=val_arg_df, \n",
    "                                                                             test_df=test_arg_df, \n",
    "                                                                             train_labels_df=train_labels_df, \n",
    "                                                                             val_labels_df=val_labels_df, \n",
    "                                                                             test_labels_df=test_labels_df, \n",
    "                                                                             one_hot_mapping=CLASS_2_ONE_HOT, \n",
    "                                                                             bert_version=\"bert-base-uncased\", \n",
    "                                                                             model_input=model_inputs[\"C\"],\n",
    "                                                                             custom_dataset_builder=CustomDataset_C,\n",
    "                                                                             batch_size=BATCH_SIZE, \n",
    "                                                                             shuffle=True)\n",
    "\n",
    "dataloader_train_CP, dataloader_val_CP, dataloader_test_CP  = build_dataloaders(train_df=train_arg_df, \n",
    "                                                                                val_df=val_arg_df, \n",
    "                                                                                test_df=test_arg_df, \n",
    "                                                                                train_labels_df=train_labels_df, \n",
    "                                                                                val_labels_df=val_labels_df, \n",
    "                                                                                test_labels_df=test_labels_df, \n",
    "                                                                                one_hot_mapping=CLASS_2_ONE_HOT, \n",
    "                                                                                bert_version=\"bert-base-uncased\", \n",
    "                                                                                model_input=model_inputs[\"CP\"],\n",
    "                                                                                custom_dataset_builder=CustomDataset_CP,\n",
    "                                                                                batch_size=BATCH_SIZE, \n",
    "                                                                                shuffle=True)\n",
    "\n",
    "dataloader_train_CPS, dataloader_val_CPS, dataloader_test_CPS  = build_dataloaders(train_df=train_arg_df, \n",
    "                                                                                   val_df=val_arg_df, \n",
    "                                                                                   test_df=test_arg_df, \n",
    "                                                                                   train_labels_df=train_labels_df, \n",
    "                                                                                   val_labels_df=val_labels_df, \n",
    "                                                                                   test_labels_df=test_labels_df, \n",
    "                                                                                   one_hot_mapping=CLASS_2_ONE_HOT, \n",
    "                                                                                   bert_version=\"bert-base-uncased\", \n",
    "                                                                                   model_input=model_inputs[\"CPS\"],\n",
    "                                                                                   custom_dataset_builder=CustomDataset_CPS,\n",
    "                                                                                   batch_size=BATCH_SIZE, \n",
    "                                                                                   shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9b4d8eb2b9080d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:45:19.405346392Z",
     "start_time": "2023-12-13T16:45:13.535600867Z"
    }
   },
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dbdf03bd612820",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Models Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3848b4411be166",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T16:45:34.405111405Z",
     "start_time": "2023-12-13T16:45:34.363675874Z"
    }
   },
   "source": [
    "####  1) Random uniform classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82f51d9c86bef3a0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T17:10:05.608368171Z",
     "start_time": "2023-12-13T17:10:05.564818892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model over all the classes: 0.06725888324873096\n",
      "\n",
      " - Openess_to_change F1: 0.4709263459646603\n",
      " - Self_enhancement F1: 0.4953258965986781\n",
      " - Conservation F1: 0.4814643653680002\n",
      " - Self_transcendence F1: 0.5120320656451882\n",
      "\n",
      "Average F1: 0.4899371683941317\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the random uniform classifier\n",
    "random_classifier = RandomUniformClassifier(N_LABELS)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_labels = random_classifier.predict(test_arg_df)\n",
    "\n",
    "# Accuracy of the Random Classifier\n",
    "accuracy = accuracy_score(test_labels_df, predicted_labels)\n",
    "print(f'Accuracy of the model over all the classes: {accuracy}\\n')\n",
    "\n",
    "# F1 scores on the different labels singularly taken \n",
    "f1_scorer = F1_Score_Multi_Labels(name='F1_macro_avg', num_labels=N_LABELS, num_classes=N_CLASSES, compute_mean=False)\n",
    "f1_scores_random_classifier = f1_scorer(torch.tensor(test_labels_df.values.tolist()), torch.tensor(predicted_labels))\n",
    "# AVG f1 score\n",
    "f1_avg_random_classifier = np.average(f1_scores_random_classifier)\n",
    "\n",
    "\n",
    "for idx, f1_score in enumerate(f1_scores_random_classifier):\n",
    "    print(f\" - {train_labels_df.columns[idx]} F1: {f1_score}\")\n",
    "\n",
    "print(f'\\nAverage F1: {f1_avg_random_classifier}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db911208037aa18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  1) Majority classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model over all the classes: 0.13642131979695432\n",
      "\n",
      " - Openess_to_change F1: 0.41150112023898433\n",
      " - Self_enhancement F1: 0.3708582834331337\n",
      " - Conservation F1: 0.4152133580705009\n",
      " - Self_transcendence F1: 0.32850447379633574\n",
      "\n",
      "Average F1: 0.3815193088847386\n"
     ]
    }
   ],
   "source": [
    "majority_classifier = MajorityClassifier()\n",
    "\n",
    "# Train the majority classifier (even though in practice, no training is needed)\n",
    "majority_classifier.fit(train_labels_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predicted_labels = majority_classifier.predict(test_labels_df)\n",
    "\n",
    "# Accuracy of the Majority Classifier\n",
    "accuracy = accuracy_score(test_labels_df, predicted_labels)\n",
    "print(f'Accuracy of the model over all the classes: {accuracy}\\n')\n",
    "\n",
    "# F1 scores on the different labels singularly taken \n",
    "f1_scorer = F1_Score_Multi_Labels(name='F1_macro_avg', num_labels=N_LABELS, num_classes=N_CLASSES, compute_mean=False)\n",
    "f1_scores_majority_classifier = f1_scorer(torch.tensor(test_labels_df.values.tolist()), torch.tensor(predicted_labels))\n",
    "# AVG F1 score\n",
    "f1_avg_majority_classifier = np.average(f1_scores_majority_classifier)\n",
    "\n",
    "\n",
    "for idx, f1_score in enumerate(f1_scores_majority_classifier):\n",
    "    print(f\" - {train_labels_df.columns[idx]} F1: {f1_score}\")\n",
    "\n",
    "print(f'\\nAverage F1: {f1_avg_majority_classifier}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-13T17:27:42.516826149Z",
     "start_time": "2023-12-13T17:27:42.311094473Z"
    }
   },
   "id": "7948530f7e667126"
  },
  {
   "cell_type": "markdown",
   "id": "ed615adcd88b156c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  3) Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185abecdef2d8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-13T16:45:06.325855033Z",
     "start_time": "2023-12-13T16:45:01.915880354Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer_test = OptimizerWrapper(torch.optim.Adam, identifier=f'lr={1e-5}', optimizer_partial_params={'lr': 1e-6})          \n",
    "criterion_test = Criterion('loss', loss_function=torch.nn.BCEWithLogitsLoss(reduction='none'), reduction_function=torch.sum)\n",
    "\n",
    "bert1 = BertOne(dropout_prob=0.3, hidden_size= 768, bert_version='bert-base-uncased').to(device)\n",
    "\n",
    "bert1_history = bert1.fit(train_loader=dataloader_train_C, \n",
    "                          val_loader=dataloader_val_C, \n",
    "                          criterion=criterion_test, \n",
    "                          metrics=[F1_Score_Multi_Labels('F1_macro_avg', num_labels=N_LABELS, num_classes=N_CLASSES)], \n",
    "                          optimizer=optimizer_test,\n",
    "                          # early_stopper=EarlyStopper(monitor='F1_macro', patience=4, delta=0, mode='max', restore_weights=True),\n",
    "                          num_epochs=200)\n",
    "\n",
    "\"\"\"\n",
    "loss homework 1 con batch size 1\n",
    "[0.4, 0.5, 0.8, ... 0.2] 46 loss\n",
    "\n",
    "loss homework 2 con batch size 1\n",
    "        [[0.4339, 0.4490],\n",
    "        [0.5538, 0.6676],\n",
    "        [0.4004, 0.3562],\n",
    "        [0.6964, 0.6620]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829599ba89a99187",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-10T18:43:13.675595100Z",
     "start_time": "2023-12-10T18:43:10.210703400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'p_d = BertOne()\\noutput1 = p_d(**encoded_input)'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Test sul modello\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config=transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "text = \"Replace me by any text you'd like pollo.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "output = model(**encoded_input)\n",
    "print(model.config)\n",
    "\"\"\"p_d = BertOne()\n",
    "output1 = p_d(**encoded_input)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OptimizerWrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m optimizer_test \u001B[38;5;241m=\u001B[39m \u001B[43mOptimizerWrapper\u001B[49m(torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam, identifier\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;241m1e-5\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, optimizer_partial_params\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m1e-8\u001B[39m})\n\u001B[1;32m      2\u001B[0m criterion_test \u001B[38;5;241m=\u001B[39m Criterion(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m, loss_function\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss(reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m), reduction_function\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mmean)\n\u001B[1;32m      4\u001B[0m bert1 \u001B[38;5;241m=\u001B[39m BertOne(dropout_prob\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.3\u001B[39m, hidden_size\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m768\u001B[39m, bert_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert-base-uncased\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'OptimizerWrapper' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import max_pool2d\n",
    "\n",
    "print(output[0].shape)\n",
    "output_2 = max_pool2d(output[0], kernel_size=(14,1))\n",
    "\n",
    "output_2[:,0,:].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-13T16:45:01.957905717Z"
    }
   },
   "id": "c2bf2f8851186caf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
